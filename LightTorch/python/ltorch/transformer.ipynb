{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=../\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTHONPATH ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ltorch backend\n"
     ]
    }
   ],
   "source": [
    "import ltorch\n",
    "from ltorch.nn import TransformerLayer\n",
    "\n",
    "# 定义模型参数\n",
    "d_model = 512  # 输入和输出特征的维度\n",
    "nhead = 8      # 多头注意力机制中的头数\n",
    "dim_feedforward = 2048  # 前馈神经网络的隐藏层维度\n",
    "dropout = 0.0  # Dropout概率\n",
    "\n",
    "ldevice = ltorch.cuda()\n",
    "ltorch_model = TransformerLayer(d_model, nhead, d_model//nhead, dim_feedforward, dropout=dropout, device=ldevice, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "device = torch.device(\"cuda\")\n",
    "torch_model = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True).to(device)\n",
    "torch_model.linear1.bias.data.zero_()\n",
    "torch_model.linear2.bias.data.zero_()\n",
    "M = torch.triu(-float(\"inf\")*torch.ones(10, 10),1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 随机生成输入数据\n",
    "batch_size = 64\n",
    "seq_len = 10\n",
    "input_size = 512\n",
    "inputs = np.random.rand(batch_size, seq_len, input_size).astype(np.float32)\n",
    "\n",
    "# 转换为torch tensor\n",
    "inputs_torch = torch.tensor(inputs, device=device)\n",
    "\n",
    "# 转换为ltorch tensor\n",
    "inputs_ltorch = ltorch.Tensor(inputs, device=ldevice, dtype=\"float32\", requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_torch = torch_model(inputs_torch, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ltorch = ltorch_model(inputs_ltorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_ltorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltorch_model.attention.k_projection.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltorch_model.attention.out_projection.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.self_attn.in_proj_weight[:512].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.self_attn.out_proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [12:57<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_acc: 0.044006704881911454, avg_loss: 7.291937828063965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [12:57<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_acc: 0.05124414721476279, avg_loss: 6.597293376922607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [12:56<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_acc: 0.05165298147765613, avg_loss: 6.587510585784912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [12:54<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_acc: 0.05151096536528266, avg_loss: 6.580854415893555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 354/727 [06:20<06:41,  1.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m train_data \u001b[38;5;241m=\u001b[39m ltorch\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mbatchify(corpus\u001b[38;5;241m.\u001b[39mtrain, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m LanguageModel(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;28mlen\u001b[39m(corpus\u001b[38;5;241m.\u001b[39mdictionary), hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, seq_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m, seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain_ptb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mltorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m evaluate_ptb(model, train_data, seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/apps/simple_ml.py:288\u001b[0m, in \u001b[0;36mtrain_ptb\u001b[0;34m(model, data, seq_len, n_epochs, optimizer, lr, weight_decay, loss_fn, clip, device, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m opt \u001b[38;5;241m=\u001b[39m optimizer(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr, weight_decay \u001b[38;5;241m=\u001b[39m weight_decay)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m--> 288\u001b[0m     avg_acc, avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mepoch_general_ptb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_acc, avg_loss\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/apps/simple_ml.py:247\u001b[0m, in \u001b[0;36mepoch_general_ptb\u001b[0;34m(data, model, seq_len, loss_fn, opt, clip, device, dtype)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m    246\u001b[0m     opt\u001b[38;5;241m.\u001b[39mreset_grad()\n\u001b[0;32m--> 247\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    250\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m*\u001b[39m batch_size)\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:296\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, out_grad)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    291\u001b[0m     out_grad \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    292\u001b[0m         out_grad\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m out_grad\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m init\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    295\u001b[0m     )\n\u001b[0;32m--> 296\u001b[0m     \u001b[43mcompute_gradient_of_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:391\u001b[0m, in \u001b[0;36mcompute_gradient_of_variables\u001b[0;34m(output_tensor, out_grad)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# compute partial ajoints for input node\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m partial_ajoints \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_as_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43majoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m in_node, partial_ajoint \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39minputs, partial_ajoints):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_to_output_grads_list:\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:60\u001b[0m, in \u001b[0;36mOp.gradient_as_tuple\u001b[0;34m(self, out_grad, node)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_as_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, node: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Convenience method to always return a tuple from gradient call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/ops/ops_mathematic.py:223\u001b[0m, in \u001b[0;36mBroadcastTo.gradient\u001b[0;34m(self, out_grad, node)\u001b[0m\n\u001b[1;32m    220\u001b[0m shrink_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, shrink_dims))\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shrink_dims) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshrink_dims\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(ori_shape)\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:349\u001b[0m, in \u001b[0;36mTensor.sum\u001b[0;34m(self, axes)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mltorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSummation\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:73\u001b[0m, in \u001b[0;36mTensorOp.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_from_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:242\u001b[0m, in \u001b[0;36mTensor.make_from_op\u001b[0;34m(op, inputs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m--> 242\u001b[0m     \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize_cached_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/autograd.py:100\u001b[0m, in \u001b[0;36mValue.realize_cached_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_data\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# note: data implicitly calls realized cached data\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize_cached_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_data\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_data\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/ops/ops_mathematic.py:242\u001b[0m, in \u001b[0;36mSummation.compute\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    240\u001b[0m         a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m axis)\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummation\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/backend_ndarray/ndarray.py:666\u001b[0m, in \u001b[0;36msummation\u001b[0;34m(a, axis, keepdims)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummation\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/LightTorch/LightTorch/python/ltorch/../ltorch/backend_ndarray/ndarray.py:579\u001b[0m, in \u001b[0;36mNDArray.sum\u001b[0;34m(self, axis, keepdims)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    578\u001b[0m     view, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce_view_out(axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims)\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ltorch\n",
    "from ltorch.apps.models import LanguageModel\n",
    "from ltorch.apps.simple_ml import train_ptb, evaluate_ptb\n",
    "\n",
    "device = ltorch.cuda()\n",
    "corpus = ltorch.data.Corpus(\"./ltorch_data/ptb\")\n",
    "train_data = ltorch.data.batchify(corpus.train, batch_size=64, device=device, dtype=\"float32\")\n",
    "model = LanguageModel(20, len(corpus.dictionary), hidden_size=32, num_layers=12, seq_model='transformer', seq_len=20, device=device)\n",
    "train_ptb(model, train_data, seq_len=20, n_epochs=10, device=device, lr=0.003, optimizer=ltorch.optim.Adam)\n",
    "evaluate_ptb(model, train_data, seq_len=20, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LightTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
