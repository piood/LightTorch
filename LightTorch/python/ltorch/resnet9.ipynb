{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=../\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTHONPATH ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ltorch backend\n",
      "Epoch: 0, Acc: 0.36926, Loss: [1.7610228]\n",
      "Epoch: 1, Acc: 0.47838, Loss: [1.4424644]\n",
      "Epoch: 2, Acc: 0.52232, Loss: [1.3144271]\n",
      "Epoch: 3, Acc: 0.55766, Loss: [1.223388]\n",
      "Epoch: 4, Acc: 0.58552, Loss: [1.1526308]\n",
      "Epoch: 5, Acc: 0.60802, Loss: [1.0963652]\n",
      "Epoch: 6, Acc: 0.62528, Loss: [1.0428902]\n",
      "Epoch: 7, Acc: 0.6457, Loss: [0.9904319]\n",
      "Epoch: 8, Acc: 0.6629, Loss: [0.94632685]\n",
      "Epoch: 9, Acc: 0.67764, Loss: [0.9094294]\n",
      "Epoch: 10, Acc: 0.68838, Loss: [0.86830944]\n",
      "Epoch: 11, Acc: 0.70258, Loss: [0.8285485]\n",
      "Epoch: 12, Acc: 0.71576, Loss: [0.79799104]\n",
      "Epoch: 13, Acc: 0.72844, Loss: [0.76214737]\n",
      "Epoch: 14, Acc: 0.73786, Loss: [0.73106116]\n",
      "Epoch: 15, Acc: 0.74862, Loss: [0.702864]\n",
      "Epoch: 16, Acc: 0.76058, Loss: [0.6702304]\n",
      "Epoch: 17, Acc: 0.76808, Loss: [0.64752674]\n",
      "Epoch: 18, Acc: 0.77886, Loss: [0.6195581]\n",
      "Epoch: 19, Acc: 0.7912, Loss: [0.588093]\n",
      "Epoch: 20, Acc: 0.796, Loss: [0.57328856]\n",
      "Epoch: 21, Acc: 0.8043, Loss: [0.5489439]\n",
      "Epoch: 22, Acc: 0.80972, Loss: [0.52895224]\n",
      "Epoch: 23, Acc: 0.8192, Loss: [0.5059653]\n",
      "Epoch: 24, Acc: 0.8243, Loss: [0.48599836]\n",
      "Epoch: 25, Acc: 0.82996, Loss: [0.47191212]\n",
      "Epoch: 26, Acc: 0.8368, Loss: [0.45641062]\n",
      "Epoch: 27, Acc: 0.83998, Loss: [0.44435847]\n",
      "Epoch: 28, Acc: 0.84746, Loss: [0.42641735]\n",
      "Epoch: 29, Acc: 0.85278, Loss: [0.41423723]\n",
      "Epoch: 30, Acc: 0.85532, Loss: [0.4006585]\n",
      "Epoch: 31, Acc: 0.8619, Loss: [0.38354626]\n",
      "Epoch: 32, Acc: 0.8633, Loss: [0.38121915]\n",
      "Epoch: 33, Acc: 0.86642, Loss: [0.3714566]\n",
      "Epoch: 34, Acc: 0.86794, Loss: [0.3685993]\n",
      "Epoch: 35, Acc: 0.87448, Loss: [0.34986824]\n",
      "Epoch: 36, Acc: 0.87508, Loss: [0.34703183]\n",
      "Epoch: 37, Acc: 0.87738, Loss: [0.3430342]\n",
      "Epoch: 38, Acc: 0.88316, Loss: [0.32727692]\n",
      "Epoch: 39, Acc: 0.88342, Loss: [0.32509005]\n",
      "Epoch: 40, Acc: 0.88592, Loss: [0.31838134]\n",
      "Epoch: 41, Acc: 0.88676, Loss: [0.31425104]\n",
      "Epoch: 42, Acc: 0.89148, Loss: [0.30165917]\n",
      "Epoch: 43, Acc: 0.8917, Loss: [0.30642065]\n",
      "Epoch: 44, Acc: 0.89472, Loss: [0.29406935]\n",
      "Epoch: 45, Acc: 0.89718, Loss: [0.2885627]\n",
      "Epoch: 46, Acc: 0.89668, Loss: [0.28734156]\n",
      "Epoch: 47, Acc: 0.89788, Loss: [0.28644618]\n",
      "Epoch: 48, Acc: 0.89404, Loss: [0.29469946]\n",
      "Epoch: 49, Acc: 0.9003, Loss: [0.2772856]\n",
      "Evaluation Acc: 0.92412, Evaluation Loss: [0.2202885]\n"
     ]
    }
   ],
   "source": [
    "import ltorch\n",
    "from ltorch.apps.models import ResNet9\n",
    "from ltorch.apps.simple_ml import train_cifar10, evaluate_cifar10\n",
    "import numpy as np\n",
    "\n",
    "device = ltorch.cuda()\n",
    "dataset = ltorch.data.CIFAR10Dataset(\"ltorch_data/cifar-10-batches-py\", train=True)\n",
    "dataloader = ltorch.data.DataLoader(\n",
    "         dataset=dataset,\n",
    "         batch_size=256,\n",
    "         shuffle=True, device=device)\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "\n",
    "loss_fn = ltorch.nn.SoftmaxLoss()\n",
    "n_epochs=50\n",
    "optimizer=ltorch.optim.Adam\n",
    "lr=0.001\n",
    "weight_decay=0.001\n",
    "\n",
    "opt = optimizer(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "for epoch in range(n_epochs):\n",
    "    correct, total_loss = 0, 0\n",
    "    device = model.device\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        opt.reset_grad()\n",
    "        X, y = batch\n",
    "        X, y = ltorch.Tensor(X, device=device), ltorch.Tensor(y, device=device)\n",
    "        out = model(X)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        correct += np.sum(np.argmax(out.numpy(), axis=1) == y.numpy())\n",
    "        total_loss += loss.data.numpy() * y.shape[0]\n",
    "    sample_nums = len(dataloader.dataset)\n",
    "    avg_acc, avg_loss =  correct / sample_nums, total_loss / sample_nums\n",
    "    print(f\"Epoch: {epoch}, Acc: {avg_acc}, Loss: {avg_loss}\")\n",
    "\n",
    "evaluate_cifar10(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [3.] pred:  [3]\n",
      "label:  [8.] pred:  [8]\n",
      "label:  [8.] pred:  [8]\n",
      "label:  [0.] pred:  [8]\n",
      "label:  [6.] pred:  [6]\n",
      "label:  [6.] pred:  [6]\n",
      "label:  [1.] pred:  [3]\n",
      "label:  [6.] pred:  [6]\n",
      "label:  [3.] pred:  [3]\n",
      "label:  [1.] pred:  [1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_dataset = ltorch.data.CIFAR10Dataset(\"ltorch_data/cifar-10-batches-py\", train=False)\n",
    "test_dataloader = ltorch.data.DataLoader(\\\n",
    "         dataset=test_dataset,\n",
    "         batch_size=1,\n",
    "         shuffle=False,)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "step = 0\n",
    "for batch in test_dataloader:\n",
    "    step += 1\n",
    "    if step > 10:\n",
    "        break\n",
    "    image = batch[0]\n",
    "    label = batch[1]\n",
    "    x, y = ltorch.Tensor(image, device=device), ltorch.Tensor(label, device=device)\n",
    "    pred = model(x)\n",
    "    print(\"label: \", y, \"pred: \", np.argmax(pred.numpy(), axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LightTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
